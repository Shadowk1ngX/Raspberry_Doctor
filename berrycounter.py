# -*- coding: utf-8 -*-
"""BerryCounter

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Np4ihNKa2mrHXG43aUQwXLBWpmbx8oNK
"""

import os
HOME = os.getcwd()

import numpy as np
import supervision as sv

from ultralytics import YOLO
from supervision.assets import download_assets, VideoAssets

SOURCE_VIDEO_PATH = f"{HOME}/TestVideo.mp4"

generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)
frame = next(generator)

sv.plot_image(frame, (12, 12))

sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)

model = YOLO("weights.pt")

results = model(frame, verbose=False)[0]
detections = sv.Detections.from_ultralytics(results)

bounding_box_annotator = sv.BoundingBoxAnnotator(thickness=4)
annotated_frame = bounding_box_annotator.annotate(frame.copy(), detections)
sv.plot_image(annotated_frame, (12, 12))

labels = [
    f"{results.names[class_id]} {confidence:0.2f}"
    for class_id, confidence
    in zip(detections.class_id, detections.confidence)
]
print(labels)
print(detections.class_id)

bounding_box_annotator = sv.BoundingBoxAnnotator(thickness=4)
label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)

annotated_frame = frame.copy()
annotated_frame = bounding_box_annotator.annotate(annotated_frame, detections)
annotated_frame = label_annotator.annotate(annotated_frame, detections, labels)
sv.plot_image(annotated_frame, (12, 12))

START = sv.Point(0, 800)
END = sv.Point(1920, 800)

line_zone = sv.LineZone(start=START, end=END)

line_zone_annotator = sv.LineZoneAnnotator(
    thickness=4,
    text_thickness=4,
    text_scale=2)

annotated_frame = frame.copy()
annotated_frame = line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)
sv.plot_image(annotated_frame, (12, 12))

byte_tracker = sv.ByteTrack()

bounding_box_annotator = sv.BoundingBoxAnnotator(thickness=4)
label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)
trace_annotator = sv.TraceAnnotator(thickness=4)

def callback(frame: np.ndarray, index: int) -> np.ndarray:
    results = model(frame, verbose=False)[0]  # Run YOLO model
    detections = sv.Detections.from_ultralytics(results)  # Convert detections

    # ✅ Filter detections to keep only specific classes
    TARGET_CLASSES = [2]  # Example: 0 = 'person', 2 = 'car' (change as needed)
    mask = np.isin(detections.class_id, TARGET_CLASSES)  # Boolean mask for filtering
    detections = detections[mask]  # Apply mask to keep only target classes

    # Update tracking with filtered detections
    detections = byte_tracker.update_with_detections(detections)

    # Generate labels for visualization
    labels = [
        f"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}"
        for confidence, class_id, tracker_id
        in zip(detections.confidence, detections.class_id, detections.tracker_id)
    ]

    # Annotate frame with detections
    annotated_frame = frame.copy()
    annotated_frame = trace_annotator.annotate(scene=annotated_frame, detections=detections)
    annotated_frame = bounding_box_annotator.annotate(scene=annotated_frame, detections=detections)
    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)

    # ✅ Trigger line zone with filtered detections
    line_zone.trigger(detections)

    # Return annotated frame with the counting line
    return line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)

TARGET_VIDEO_PATH = f"{HOME}/count-objects-crossing-the-line-result.mp4"

sv.process_video(
    source_path = SOURCE_VIDEO_PATH,
    target_path = TARGET_VIDEO_PATH,
    callback=callback
)